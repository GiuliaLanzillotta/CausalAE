model_params:
  name: 'VAE'
  beta: 4.0
  latent_size: 32
  enc_depth: 6 #number of convolutional layers in the encoder
  dec_depth: 6
  pool_every: 2

opt_params:
  LR: 0.0001
  weight_decay: 0.0
  scheduler_gamma: 0.95
  KL_decay: 0.9


data_params:
  dataset_name: MNIST
  batch_size: 144 # Better to have a square number
  test_batch_size: 144

trainer_params:
  gpus: 1
  max_epochs: 50

logging_params:
  save_dir: "logs/"
  name: "BetaVAE"
  manual_seed: 1265
  version: v14
  plot_every: 1

