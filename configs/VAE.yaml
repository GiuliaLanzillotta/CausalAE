model_params:
  name: 'VAE'
  beta: 4.0
  latent_size: 12
  enc_depth: 12 #number of convolutional layers in the encoder
  dec_depth: 12
  pool_every: 3

opt_params:
  LR: 0.0001
  weight_decay: 0.0
  scheduler_gamma: 0.95
  KL_decay: 0.9


data_params:
  dataset_name: MNIST
  batch_size: 144 # Better to have a square number
  test_batch_size: 144

trainer_params:
  gpus: 1
  max_epochs: 100

logging_params:
  save_dir: "logs/"
  name: "BetaVAE"
  manual_seed: 1265
  version: cluster1
  score_every: 1000


vis_params:
  save_dir: "vis/"
  plot_every: 20
  num_animations: 5
  num_frames: 5
  fpd: 10
  num_points_irs: 10000


