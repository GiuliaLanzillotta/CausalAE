model_params:
  name: 'SAE'
  latent_dim: 16
  channels_list_enc: [64, 64, 64, 64]
  channels_list_dec: [64, 64, 64, 64]
  filter_size: 3
  padding_enc: 1
  stride_enc: 2
  stride_dec: 1
  unit_dim: 4
  upsampling_factor: 2
  latent_vecs: 128 # for hybrid sampling

opt_params:
  LR: 0.0005
  weight_decay: 0.0
  scheduler_gamma: 0.95
  auto_epochs: -1


data_params:
  dataset_name: MNIST
  batch_size: 144 # Better to have a square number
  test_batch_size: 144
  train_split: 0.7
  heldout: False
  real: False
  subset: False #limit number of samples to 200.000 (to avoid memory errors)

trainer_params:
  gpus: 1
  max_epochs: 100

logging_params:
  save_dir: "logs/"
  name: "SAE"
  manual_seed: 1265
  version: v3
  plot_every: 5

