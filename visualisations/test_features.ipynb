{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Testing new visualisation features\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "_cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Giulia\\\\Study\\\\projects\\\\research\\\\SAE'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(Path(_cwd)/'..') # .\\SAE\\\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt\n",
    "from models import GenerativeAE\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments import EvaluationManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'experiments.EvaluationManager' from 'C:\\\\Users\\\\Giulia\\\\Study\\\\projects\\\\research\\\\SAE\\\\experiments\\\\EvaluationManager.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(EvaluationManager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'metrics.score_disentanglement' from 'C:\\\\Users\\\\Giulia\\\\Study\\\\projects\\\\research\\\\SAE\\\\metrics\\\\score_disentanglement.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metrics import score_disentanglement \n",
    "importlib.reload(score_disentanglement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.EvaluationManager import ModelHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing config file: loading.\n",
      "====== Opening RFD Dataset - train ======\n",
      "Factors dictionary already created. Proceed to reading.\n",
      "====== Opening RFD Dataset - test ======\n",
      "Factors dictionary already created. Proceed to reading.\n",
      "====== Opening RFD Dataset - HC ======\n",
      "Factors dictionary already created. Proceed to reading.\n",
      "====== Opening RFD Dataset - real ======\n",
      "Categorising labels...\n",
      "Factors dictionary already created. Proceed to reading.\n",
      "BaseSAE model loaded.\n"
     ]
    }
   ],
   "source": [
    "handler = ModelHandler(model_name=\"BaseSAE\", model_version=\"v16\", data=\"RFDh5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available checkpoints at logs\\BaseSAE\\v16_RFDh5\\checkpoints :\n",
      "['logs\\\\BaseSAE\\\\v16_RFDh5\\\\checkpoints\\\\epoch=0-step=1799-v1.ckpt', 'logs\\\\BaseSAE\\\\v16_RFDh5\\\\checkpoints\\\\epoch=0-step=1799.ckpt', 'logs\\\\BaseSAE\\\\v16_RFDh5\\\\checkpoints\\\\epoch=0-step=198.ckpt', 'logs\\\\BaseSAE\\\\v16_RFDh5\\\\checkpoints\\\\epoch=1-step=1998.ckpt']\n"
     ]
    }
   ],
   "source": [
    "checkpoints = handler.list_available_checkpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading latest checkpoint at logs\\BaseSAE\\v16_RFDh5\\checkpoints\\epoch=1-step=1998.ckpt .\n",
      "====== Opening RFD Dataset - train ======\n",
      "Factors dictionary already created. Proceed to reading.\n",
      "====== Opening RFD Dataset - test ======\n",
      "Factors dictionary already created. Proceed to reading.\n",
      "====== Opening RFD Dataset - HC ======\n",
      "Factors dictionary already created. Proceed to reading.\n",
      "====== Opening RFD Dataset - real ======\n",
      "Categorising labels...\n",
      "Factors dictionary already created. Proceed to reading.\n"
     ]
    }
   ],
   "source": [
    "handler.load_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring model disentanglement.\n",
      "DCI scoring\n",
      "BetaVAE scoring\n",
      "Total of 113 substitutions done.\n",
      "Total of 125 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 124 substitutions done.\n",
      "Total of 126 substitutions done.\n",
      "Total of 125 substitutions done.\n",
      "Total of 108 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 126 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 123 substitutions done.\n",
      "Total of 121 substitutions done.\n",
      "Total of 114 substitutions done.\n",
      "Total of 122 substitutions done.\n",
      "Total of 126 substitutions done.\n",
      "Total of 122 substitutions done.\n",
      "Total of 126 substitutions done.\n",
      "Total of 125 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 127 substitutions done.\n",
      "Total of 117 substitutions done.\n",
      "Total of 113 substitutions done.\n",
      "Total of 125 substitutions done.\n",
      "Total of 128 substitutions done.\n",
      "Total of 125 substitutions done.\n",
      "Total of 120 substitutions done.\n",
      "Total of 128 substitutions done.\n",
      "Total of 107 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 115 substitutions done.\n",
      "Total of 124 substitutions done.\n",
      "Total of 124 substitutions done.\n",
      "Total of 109 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 120 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 124 substitutions done.\n",
      "Total of 125 substitutions done.\n",
      "Total of 123 substitutions done.\n",
      "Total of 123 substitutions done.\n",
      "Total of 124 substitutions done.\n",
      "Total of 119 substitutions done.\n",
      "Total of 109 substitutions done.\n",
      "Total of 123 substitutions done.\n",
      "Total of 119 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 118 substitutions done.\n",
      "Total of 124 substitutions done.\n",
      "Total of 125 substitutions done.\n",
      "Total of 121 substitutions done.\n",
      "Total of 115 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 122 substitutions done.\n",
      "Total of 122 substitutions done.\n",
      "Total of 121 substitutions done.\n",
      "Total of 121 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 122 substitutions done.\n",
      "Total of 121 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 108 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 124 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 112 substitutions done.\n",
      "Total of 109 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 124 substitutions done.\n",
      "Total of 111 substitutions done.\n",
      "Total of 110 substitutions done.\n",
      "Total of 126 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 122 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 125 substitutions done.\n",
      "Total of 123 substitutions done.\n",
      "Total of 123 substitutions done.\n",
      "Total of 110 substitutions done.\n",
      "Total of 118 substitutions done.\n",
      "Total of 107 substitutions done.\n",
      "Total of 122 substitutions done.\n",
      "Total of 122 substitutions done.\n",
      "Total of 113 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 107 substitutions done.\n",
      "Total of 109 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 121 substitutions done.\n",
      "Total of 113 substitutions done.\n",
      "Total of 122 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 108 substitutions done.\n",
      "Total of 118 substitutions done.\n",
      "Total of 121 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 116 substitutions done.\n",
      "Total of 116 substitutions done.\n",
      "Total of 121 substitutions done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\giulia\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\giulia\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 0 substitutions done.\n",
      "Total of 124 substitutions done.\n",
      "Total of 109 substitutions done.\n",
      "Total of 115 substitutions done.\n",
      "Total of 120 substitutions done.\n",
      "Total of 111 substitutions done.\n",
      "Total of 123 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 119 substitutions done.\n",
      "Total of 111 substitutions done.\n",
      "Total of 124 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 121 substitutions done.\n",
      "Total of 128 substitutions done.\n",
      "Total of 110 substitutions done.\n",
      "Total of 119 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 123 substitutions done.\n",
      "Total of 121 substitutions done.\n",
      "Total of 110 substitutions done.\n",
      "Total of 123 substitutions done.\n",
      "Total of 126 substitutions done.\n",
      "Total of 110 substitutions done.\n",
      "Total of 124 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 122 substitutions done.\n",
      "Total of 114 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 121 substitutions done.\n",
      "Total of 123 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 126 substitutions done.\n",
      "Total of 111 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 125 substitutions done.\n",
      "Total of 121 substitutions done.\n",
      "Total of 121 substitutions done.\n",
      "Total of 113 substitutions done.\n",
      "Total of 113 substitutions done.\n",
      "Total of 123 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 123 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 124 substitutions done.\n",
      "Total of 123 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "Total of 124 substitutions done.\n",
      "Total of 0 substitutions done.\n",
      "IRS scoring\n",
      "MIG scoring\n",
      "Modularity explicitness scoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\giulia\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\giulia\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\giulia\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\giulia\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\giulia\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\giulia\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\giulia\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\giulia\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\giulia\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\giulia\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\giulia\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\giulia\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\giulia\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\giulia\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAP scoring\n"
     ]
    }
   ],
   "source": [
    "scores = handler.score_model(FID=False, disentanglement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DCI': 0.014383662883409722,\n",
       " 'BVAE': 0.1,\n",
       " 'IRS': 0.8549604247709786,\n",
       " 'MIG': 0.0033707486570184395,\n",
       " 'ModExp': 0.6239185859845178,\n",
       " 'SAP': 0.007142857142857145,\n",
       " 'extra_disentanglement': {'DCI': {'informativeness_train': 1.0,\n",
       "   'informativeness_test': 1.0,\n",
       "   'disentanglement': 0.014383662883409722,\n",
       "   'completeness': 0.12087524165657787,\n",
       "   'extras': {'importance_matrix': array([[0.04763685, 0.03262623, 0.03882734, 0.03935826, 0.05263071,\n",
       "            0.03768331, 0.06064605],\n",
       "           [0.02947808, 0.03315997, 0.03639624, 0.04047136, 0.03771441,\n",
       "            0.02371647, 0.02694258],\n",
       "           [0.00551655, 0.0035995 , 0.00612127, 0.01304157, 0.00695992,\n",
       "            0.00714957, 0.00810576],\n",
       "           [0.01059379, 0.00943959, 0.00942289, 0.0099881 , 0.01688889,\n",
       "            0.01349323, 0.00792252],\n",
       "           [0.01579977, 0.03191805, 0.02944682, 0.02776944, 0.02790961,\n",
       "            0.02847346, 0.02880594],\n",
       "           [0.00670811, 0.00755591, 0.007987  , 0.01646801, 0.01656251,\n",
       "            0.00877177, 0.00559744],\n",
       "           [0.01471343, 0.01635537, 0.01319934, 0.01292989, 0.01533128,\n",
       "            0.01209064, 0.01485882],\n",
       "           [0.04163628, 0.05933328, 0.07174088, 0.05782804, 0.05399895,\n",
       "            0.03656835, 0.03929287],\n",
       "           [0.01699037, 0.0140854 , 0.0143542 , 0.02415545, 0.02252389,\n",
       "            0.02558853, 0.02029481],\n",
       "           [0.00286323, 0.00969239, 0.00752725, 0.00832794, 0.00858851,\n",
       "            0.00198366, 0.01015947],\n",
       "           [0.01083805, 0.00949645, 0.00709648, 0.00922118, 0.00898663,\n",
       "            0.00833787, 0.00894804],\n",
       "           [0.00833336, 0.00751815, 0.0095521 , 0.01093874, 0.01672101,\n",
       "            0.01299958, 0.00964502],\n",
       "           [0.04354177, 0.05179531, 0.05682238, 0.05533054, 0.05742085,\n",
       "            0.07460697, 0.05457739],\n",
       "           [0.0125023 , 0.01613019, 0.01239092, 0.01054037, 0.0111229 ,\n",
       "            0.01618944, 0.01058737],\n",
       "           [0.11086272, 0.14689353, 0.05562817, 0.11052875, 0.10971164,\n",
       "            0.07220525, 0.11928092],\n",
       "           [0.01736016, 0.00785616, 0.02041369, 0.01089227, 0.01483599,\n",
       "            0.03481214, 0.0166848 ],\n",
       "           [0.00985489, 0.01675113, 0.01785655, 0.01350117, 0.01717435,\n",
       "            0.02221928, 0.00491322],\n",
       "           [0.07804399, 0.06446774, 0.0772964 , 0.09545737, 0.06298401,\n",
       "            0.07959788, 0.10129066],\n",
       "           [0.00828571, 0.01142783, 0.00939186, 0.00667323, 0.00957162,\n",
       "            0.01330204, 0.00569023],\n",
       "           [0.05258242, 0.03358262, 0.04965982, 0.02613546, 0.03360559,\n",
       "            0.02964949, 0.0289744 ],\n",
       "           [0.01214711, 0.01486937, 0.02235269, 0.01506644, 0.02441838,\n",
       "            0.02002715, 0.0117352 ],\n",
       "           [0.01646689, 0.00905881, 0.01921578, 0.00702956, 0.00988732,\n",
       "            0.0069299 , 0.01214244],\n",
       "           [0.01449992, 0.01056561, 0.01138402, 0.00730258, 0.01181363,\n",
       "            0.02087874, 0.01418719],\n",
       "           [0.02347847, 0.01355745, 0.0256456 , 0.01147262, 0.02156359,\n",
       "            0.01066205, 0.01009383],\n",
       "           [0.01072413, 0.01184047, 0.01218573, 0.01246389, 0.01136694,\n",
       "            0.01248058, 0.00493369],\n",
       "           [0.00478584, 0.0080293 , 0.0099936 , 0.00896159, 0.01203509,\n",
       "            0.01123013, 0.00211424],\n",
       "           [0.01258753, 0.01659811, 0.02888202, 0.02677839, 0.02511483,\n",
       "            0.02073029, 0.0291161 ],\n",
       "           [0.00931107, 0.01524104, 0.01863671, 0.01862772, 0.01585593,\n",
       "            0.01478201, 0.01258066],\n",
       "           [0.01462047, 0.02983201, 0.02821772, 0.01044938, 0.02897979,\n",
       "            0.01897306, 0.02356724],\n",
       "           [0.06227589, 0.04869953, 0.07671711, 0.05449506, 0.06143605,\n",
       "            0.05473744, 0.04770922],\n",
       "           [0.11871332, 0.12120737, 0.10227834, 0.08242141, 0.07851226,\n",
       "            0.1098997 , 0.09408192],\n",
       "           [0.15624755, 0.11681615, 0.09335906, 0.14537421, 0.09777293,\n",
       "            0.13923   , 0.15451994]]),\n",
       "    'informativeness_train_per_factor': array([1., 1., 1., 1., 1., 1., 1.]),\n",
       "    'informativeness_test_per_factor': array([1., 1., 1., 1., 1., 1., 1.]),\n",
       "    'disentanglement_loo_factor': array([0.0153328 , 0.01531235, 0.01418132, 0.01580004, 0.01604775,\n",
       "           0.01462977, 0.01505183]),\n",
       "    'disentanglement_loo_latent': array([0.01455605, 0.01460238, 0.01423903, 0.0143685 , 0.01452972,\n",
       "           0.01408841, 0.01455499, 0.01442604, 0.01442115, 0.01407986,\n",
       "           0.01448194, 0.01434776, 0.01489164, 0.01446917, 0.01371277,\n",
       "           0.01375222, 0.01402579, 0.01502143, 0.01434897, 0.01426781,\n",
       "           0.01430916, 0.01413703, 0.01427195, 0.01403452, 0.01436376,\n",
       "           0.01409052, 0.01428716, 0.01443142, 0.01406952, 0.0148832 ,\n",
       "           0.01530271, 0.01511269]),\n",
       "    'disentanglement_loo_factor_latent': array([[0.01542309, 0.01561421, 0.01426455, 0.0159509 , 0.0162285 ,\n",
       "            0.01475569, 0.01539647],\n",
       "           [0.0155376 , 0.01549049, 0.01433754, 0.01607516, 0.01628116,\n",
       "            0.01495511, 0.01529409],\n",
       "           [0.01515629, 0.0152351 , 0.0139807 , 0.0157998 , 0.01584984,\n",
       "            0.01442057, 0.01484913],\n",
       "           [0.01528375, 0.01527908, 0.01413536, 0.01576294, 0.01613457,\n",
       "            0.01459093, 0.01505987],\n",
       "           [0.01577264, 0.01544792, 0.01425841, 0.01591651, 0.01617111,\n",
       "            0.01471465, 0.01514951],\n",
       "           [0.01500206, 0.014949  , 0.01379367, 0.01558637, 0.01584156,\n",
       "            0.01423028, 0.01477765],\n",
       "           [0.01550785, 0.01549894, 0.01434662, 0.01599217, 0.01623514,\n",
       "            0.01481854, 0.01522311],\n",
       "           [0.01537028, 0.01525267, 0.01437865, 0.01574784, 0.01598315,\n",
       "            0.01479788, 0.01514335],\n",
       "           [0.01535093, 0.01541327, 0.01424825, 0.01583912, 0.01606516,\n",
       "            0.01468026, 0.01503498],\n",
       "           [0.01510544, 0.01495076, 0.01376859, 0.01540727, 0.01566138,\n",
       "            0.01449578, 0.01470564],\n",
       "           [0.01544604, 0.01541069, 0.01429698, 0.01590228, 0.01615254,\n",
       "            0.01472593, 0.01514769],\n",
       "           [0.0152956 , 0.01530424, 0.014103  , 0.0157278 , 0.01611823,\n",
       "            0.01456258, 0.01498178],\n",
       "           [0.01601809, 0.01581601, 0.01458266, 0.01630277, 0.0165595 ,\n",
       "            0.01532512, 0.01551394],\n",
       "           [0.01540476, 0.01541941, 0.01423891, 0.01590575, 0.0161447 ,\n",
       "            0.0147298 , 0.01514647],\n",
       "           [0.01415977, 0.01499577, 0.01456895, 0.01467852, 0.01495069,\n",
       "            0.01407967, 0.01393278],\n",
       "           [0.01448166, 0.01484568, 0.01332727, 0.01513174, 0.01524009,\n",
       "            0.01448802, 0.01419957],\n",
       "           [0.01494304, 0.01482698, 0.01369793, 0.01531826, 0.01557895,\n",
       "            0.0142978 , 0.01503478],\n",
       "           [0.0158976 , 0.01609828, 0.0146502 , 0.01652139, 0.0169433 ,\n",
       "            0.01512658, 0.01583937],\n",
       "           [0.01526937, 0.01526363, 0.01409961, 0.01578144, 0.01598343,\n",
       "            0.01463278, 0.01507008],\n",
       "           [0.01540243, 0.01507474, 0.01410205, 0.01576493, 0.01583796,\n",
       "            0.01443688, 0.01489313],\n",
       "           [0.01529175, 0.01519158, 0.01408183, 0.01568447, 0.01604531,\n",
       "            0.01448948, 0.01502292],\n",
       "           [0.01507856, 0.01500323, 0.01404536, 0.01558088, 0.01572767,\n",
       "            0.0144016 , 0.01470256],\n",
       "           [0.01515926, 0.01516414, 0.01400118, 0.01579848, 0.01588629,\n",
       "            0.01465371, 0.01487191],\n",
       "           [0.01496459, 0.01486174, 0.0138865 , 0.01542781, 0.01563016,\n",
       "            0.01427413, 0.01473387],\n",
       "           [0.01527627, 0.01525741, 0.0141172 , 0.0157565 , 0.01599856,\n",
       "            0.01457391, 0.01522263],\n",
       "           [0.01503391, 0.01491741, 0.01379355, 0.01541075, 0.01573789,\n",
       "            0.01427885, 0.01500272],\n",
       "           [0.01546716, 0.01524106, 0.01403342, 0.01564684, 0.0158808 ,\n",
       "            0.01443969, 0.0149291 ],\n",
       "           [0.01549898, 0.01532809, 0.01421703, 0.01585921, 0.01607541,\n",
       "            0.01463625, 0.01509284],\n",
       "           [0.01504486, 0.01496683, 0.01376548, 0.01578911, 0.01569239,\n",
       "            0.01418352, 0.01458383],\n",
       "           [0.01579344, 0.01588236, 0.01483688, 0.01630629, 0.01654807,\n",
       "            0.01506084, 0.01562895],\n",
       "           [0.01629761, 0.01631979, 0.01488891, 0.01696886, 0.01736386,\n",
       "            0.01541095, 0.01590953],\n",
       "           [0.01608266, 0.01591601, 0.01528048, 0.01643762, 0.01726082,\n",
       "            0.01504054, 0.01572646]]),\n",
       "    'completeness_loo_factor': array([0.11670177, 0.11861503, 0.12546495, 0.11995845, 0.12655915,\n",
       "           0.12254395, 0.11628339]),\n",
       "    'completeness_loo_latent': array([0.12659182, 0.12593416, 0.11870169, 0.12065215, 0.1251639 ,\n",
       "           0.1199829 , 0.12196143, 0.12642856, 0.12355113, 0.11850454,\n",
       "           0.11975633, 0.12051546, 0.12646213, 0.1213853 , 0.11689679,\n",
       "           0.122571  , 0.1217969 , 0.12347904, 0.11977792, 0.12608029,\n",
       "           0.12279886, 0.12069781, 0.12133576, 0.12246179, 0.1205426 ,\n",
       "           0.11912141, 0.12420824, 0.12216441, 0.12392043, 0.12633637,\n",
       "           0.1186356 , 0.10896041]),\n",
       "    'completeness_loo_factor_latent': array([[0.12213282, 0.12428388, 0.13143236, 0.12560712, 0.13254449,\n",
       "            0.12835859, 0.12179222],\n",
       "           [0.1216202 , 0.12353909, 0.1306293 , 0.12484479, 0.13175177,\n",
       "            0.12789361, 0.12124996],\n",
       "           [0.11460232, 0.11676916, 0.12345029, 0.1173    , 0.1244801 ,\n",
       "            0.12038031, 0.11393052],\n",
       "           [0.11641315, 0.11845471, 0.12544892, 0.11978302, 0.12607834,\n",
       "            0.12217753, 0.11620134],\n",
       "           [0.12127047, 0.12268035, 0.12983811, 0.12417107, 0.13101409,\n",
       "            0.12683394, 0.12033221],\n",
       "           [0.1159647 , 0.11783681, 0.12478336, 0.11859188, 0.12530817,\n",
       "            0.12173709, 0.11564961],\n",
       "           [0.11765574, 0.11952334, 0.12672054, 0.12109939, 0.12771068,\n",
       "            0.12380319, 0.11721908],\n",
       "           [0.12191728, 0.12401887, 0.13150247, 0.12542892, 0.13241455,\n",
       "            0.12819849, 0.12148928],\n",
       "           [0.11935904, 0.12149284, 0.12853526, 0.12241022, 0.12926084,\n",
       "            0.12502299, 0.11877446],\n",
       "           [0.11469074, 0.11594092, 0.12308371, 0.11741708, 0.12410207,\n",
       "            0.1207621 , 0.11353658],\n",
       "           [0.11536108, 0.11741063, 0.12459531, 0.1188007 , 0.12554197,\n",
       "            0.12150766, 0.11508029],\n",
       "           [0.11643469, 0.11845971, 0.12527733, 0.11955262, 0.12592594,\n",
       "            0.12204897, 0.11590028],\n",
       "           [0.12192007, 0.12397609, 0.13134004, 0.12543783, 0.13251552,\n",
       "            0.12852296, 0.12150019],\n",
       "           [0.11712722, 0.11886764, 0.12609385, 0.12059496, 0.127302  ,\n",
       "            0.12287875, 0.11683301],\n",
       "           [0.11231964, 0.11665139, 0.12037239, 0.11596409, 0.12334536,\n",
       "            0.11736569, 0.11230812],\n",
       "           [0.11820761, 0.12081466, 0.12706622, 0.12194916, 0.12847396,\n",
       "            0.12366624, 0.11781206],\n",
       "           [0.11778821, 0.11930964, 0.12626629, 0.12087055, 0.12742098,\n",
       "            0.12308711, 0.11781998],\n",
       "           [0.11878351, 0.12055977, 0.12837821, 0.12295965, 0.12927397,\n",
       "            0.12523841, 0.11918825],\n",
       "           [0.11558598, 0.11729149, 0.12442072, 0.11905108, 0.12552075,\n",
       "            0.12116688, 0.11540449],\n",
       "           [0.12159807, 0.12369117, 0.13074041, 0.12527879, 0.13201433,\n",
       "            0.12789255, 0.12134489],\n",
       "           [0.11877902, 0.12057428, 0.12725107, 0.12194303, 0.12829846,\n",
       "            0.12434881, 0.11837726],\n",
       "           [0.11610034, 0.11853769, 0.12490487, 0.12008892, 0.126585  ,\n",
       "            0.12274031, 0.11592826],\n",
       "           [0.11694481, 0.11916092, 0.12610727, 0.12080722, 0.12719576,\n",
       "            0.12260025, 0.11653552],\n",
       "           [0.11782977, 0.1202614 , 0.12674021, 0.12178025, 0.1280082 ,\n",
       "            0.12449565, 0.11810672],\n",
       "           [0.11627701, 0.11815002, 0.12511418, 0.11947847, 0.12628779,\n",
       "            0.12211469, 0.11637049],\n",
       "           [0.11516725, 0.11679412, 0.12360173, 0.11808214, 0.12456572,\n",
       "            0.12053869, 0.11508835],\n",
       "           [0.12036958, 0.12210944, 0.12871467, 0.1230899 , 0.12995534,\n",
       "            0.12597379, 0.11923587],\n",
       "           [0.11825866, 0.11981872, 0.12665903, 0.12102084, 0.12792315,\n",
       "            0.12387079, 0.11759132],\n",
       "           [0.11990906, 0.12129141, 0.1283929 , 0.1235566 , 0.12950073,\n",
       "            0.12571466, 0.11906622],\n",
       "           [0.12188463, 0.12381285, 0.13155337, 0.12528205, 0.13242657,\n",
       "            0.12805566, 0.12130885],\n",
       "           [0.11478156, 0.11706192, 0.12377165, 0.11679193, 0.12410679,\n",
       "            0.1208582 , 0.11310019],\n",
       "           [0.10590613, 0.10543583, 0.11220667, 0.10885762, 0.11368046,\n",
       "            0.11141596, 0.10529171]]),\n",
       "    'informativeness_train': 1.0,\n",
       "    'informativeness_test': 1.0,\n",
       "    'disentanglement': 0.014383662883409722,\n",
       "    'completeness': 0.12087524165657787}},\n",
       "  'BVAE': {'train_accuracy': 0.24, 'eval_accuracy': 0.1},\n",
       "  'IRS': {'IRS': 0.8549604247709786, 'num_active_dims': 64.07138},\n",
       "  'MIG': {'discrete_mig': 0.0033707486570184395,\n",
       "   'extras': {'mutual_information_matrix': array([[0.50642112, 1.3472975 , 1.81682333, 1.38202066, 1.27455944,\n",
       "            1.40257025, 0.56992225],\n",
       "           [0.57082695, 1.44160682, 1.96019483, 1.49713103, 1.44803556,\n",
       "            1.5099205 , 0.65213784],\n",
       "           [0.63555906, 1.3334436 , 1.9063552 , 1.38405531, 1.35914703,\n",
       "            1.46346823, 0.59973244],\n",
       "           [0.60135482, 1.35515977, 1.90164216, 1.41758835, 1.3601355 ,\n",
       "            1.4751308 , 0.6198584 ],\n",
       "           [0.54359655, 1.13436013, 1.69877359, 1.174218  , 1.20257294,\n",
       "            1.22660443, 0.5219064 ],\n",
       "           [0.53430223, 1.23195322, 1.82903743, 1.24133815, 1.27042863,\n",
       "            1.36943987, 0.55536798],\n",
       "           [0.58320352, 1.14188845, 1.77037214, 1.20945814, 1.19709322,\n",
       "            1.23662063, 0.53984043],\n",
       "           [0.56752733, 1.33503453, 1.89009003, 1.40084128, 1.35727848,\n",
       "            1.42163828, 0.62653271],\n",
       "           [0.59732336, 1.4144144 , 1.96557926, 1.50552639, 1.43466647,\n",
       "            1.504249  , 0.62983912],\n",
       "           [0.54573588, 1.32230425, 1.85596143, 1.38286355, 1.32309399,\n",
       "            1.48852224, 0.55422539],\n",
       "           [0.54307589, 1.10774889, 1.79780488, 1.21458237, 1.19185589,\n",
       "            1.23832321, 0.52653028],\n",
       "           [0.55596876, 1.23407381, 1.89604507, 1.37202207, 1.30832465,\n",
       "            1.39556695, 0.62404794],\n",
       "           [0.52894304, 1.31087515, 1.7821558 , 1.36231275, 1.32057573,\n",
       "            1.39386128, 0.61839076],\n",
       "           [0.58726416, 1.24914007, 1.90954063, 1.31774651, 1.28216413,\n",
       "            1.41751435, 0.58640551],\n",
       "           [0.53584319, 1.24399991, 1.6180341 , 1.29799968, 1.24194804,\n",
       "            1.25262163, 0.58964744],\n",
       "           [0.51751791, 1.17638213, 1.85333867, 1.32498126, 1.23149547,\n",
       "            1.28857017, 0.60027284],\n",
       "           [0.60467999, 1.33538244, 1.88556676, 1.40398888, 1.33617219,\n",
       "            1.48644502, 0.59290028],\n",
       "           [0.34626546, 0.83676217, 1.15523348, 0.90479056, 0.87313287,\n",
       "            0.98809586, 0.37885586],\n",
       "           [0.51374585, 1.17061269, 1.85133896, 1.23459366, 1.17371915,\n",
       "            1.2875923 , 0.51297196],\n",
       "           [0.60042897, 1.32429622, 1.81323488, 1.41109298, 1.3632028 ,\n",
       "            1.39909801, 0.59469393],\n",
       "           [0.60320084, 1.40439536, 1.95507724, 1.4716155 , 1.43700316,\n",
       "            1.49661339, 0.61037206],\n",
       "           [0.61062854, 1.35466017, 1.95373394, 1.48037531, 1.39145395,\n",
       "            1.48529038, 0.59039632],\n",
       "           [0.54485654, 1.23716939, 1.87319021, 1.35504974, 1.31142022,\n",
       "            1.40902638, 0.59107276],\n",
       "           [0.49780771, 1.16246534, 1.85573497, 1.27433392, 1.2141192 ,\n",
       "            1.28574373, 0.52810459],\n",
       "           [0.6163491 , 1.30303536, 1.86037528, 1.41255833, 1.35510549,\n",
       "            1.45032821, 0.60607197],\n",
       "           [0.5394608 , 1.27574828, 1.92002307, 1.37047788, 1.35963646,\n",
       "            1.43651491, 0.60407553],\n",
       "           [0.5222095 , 1.11179618, 1.80257868, 1.24008387, 1.19967291,\n",
       "            1.21853286, 0.5351173 ],\n",
       "           [0.61571015, 1.35410278, 1.90847307, 1.43684279, 1.34380217,\n",
       "            1.48539278, 0.60785089],\n",
       "           [0.58906011, 1.4321852 , 1.90847944, 1.46824708, 1.39006653,\n",
       "            1.51924721, 0.65028037],\n",
       "           [0.48495587, 0.97793131, 1.63093038, 1.074317  , 1.06218138,\n",
       "            1.06919098, 0.49455817],\n",
       "           [0.29697476, 0.80368499, 1.20880812, 0.8667872 , 0.87133859,\n",
       "            0.91817779, 0.36317184],\n",
       "           [0.24312423, 0.85081661, 1.19123426, 0.87520959, 0.70913091,\n",
       "            0.88749236, 0.35348409]]), 'discrete_mig': 0.0033707486570184395}},\n",
       "  'ModExp': {'modularity_score': 0.6239185859845178,\n",
       "   'explicitness_score_train': 0.7410302720422434,\n",
       "   'explicitness_score_test': 0.7410302720422434},\n",
       "  'SAP': {'SAP_score': 0.007142857142857145}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['extra_disentanglement'] =None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "base_path = Path(handler.config['logging_params']['save_dir']) / \\\n",
    "                        handler.config['logging_params']['name'] / \\\n",
    "                        handler.config['logging_params']['version'] / \"scoring.json\"\n",
    "with open(base_path, 'w') as o:\n",
    "    json.dump(scores, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
